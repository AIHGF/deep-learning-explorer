{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN\n",
    "\n",
    "This notebook shows how you can train a Mask R-CNN object detection and segementation model on your own data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.insert(0, '../libraries')\n",
    "from mrcnn.config import Config\n",
    "import mrcnn.utils as utils\n",
    "import mrcnn.model as modellib\n",
    "import mrcnn.visualize as visualize\n",
    "from mrcnn.model import log\n",
    "import mcoco.coco as coco\n",
    "import mextra.utils as extra_utils\n",
    "\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "HOME_DIR = '/home/keras'\n",
    "DATA_DIR = os.path.join(HOME_DIR, \"data/shapes\")\n",
    "MODEL_DIR = os.path.join(DATA_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(HOME_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "Organize the dataset using the following structure:\n",
    "\n",
    "```\n",
    "DATA_DIR\n",
    "│\n",
    "└───annotations\n",
    "│   │   instances_<subset><year>.json\n",
    "│   \n",
    "└───<subset><year>\n",
    "    │   image021.jpeg\n",
    "    │   image022.jpeg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = coco.CocoDataset()\n",
    "dataset_train.load_coco(COCO_DIR, subset=\"shapes_train\", year=\"2018\")\n",
    "dataset_train.prepare()\n",
    "\n",
    "dataset_validate = coco.CocoDataset()\n",
    "dataset_validate.load_coco(COCO_DIR, subset=\"shapes_validate\", year=\"2018\")\n",
    "dataset_validate.prepare()\n",
    "\n",
    "dataset_test = coco.CocoDataset()\n",
    "dataset_test.load_coco(COCO_DIR, subset=\"shapes_test\", year=\"2018\")\n",
    "dataset_test.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display random samples\n",
    "image_ids = np.random.choice(dataset_train.image_ids, 4)\n",
    "for image_id in image_ids:\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RPN_ANCHOR_TEMPLATE = (1, 2, 4, 8, 16) # anchor size in pixels\n",
    "\n",
    "class ShapesConfig(Config):\n",
    "    \"\"\"Configuration for training on the shapes dataset.\n",
    "    \"\"\"\n",
    "    NAME = \"shapes\"\n",
    "\n",
    "    # Train on 1 GPU and 2 images per GPU. Put multiple images on each\n",
    "    # GPU if the images are small. Batch size is 8 (GPUs * images/GPU).\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 2\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 3  # background + 3 shapes (triangles, circles, and squares)\n",
    "\n",
    "    # Use smaller images for faster training. \n",
    "    IMAGE_MAX_DIM = 512\n",
    "    IMAGE_MIN_DIM = 512\n",
    "    \n",
    "    # Use smaller anchors because our image and objects are small\n",
    "    RPN_ANCHOR_SCALES = tuple(i * 32 for i in RPN_ANCHOR_TEMPLATE)\n",
    "\n",
    "    # Aim to allow ROI sampling to pick 33% positive ROIs.\n",
    "    TRAIN_ROIS_PER_IMAGE = 32\n",
    "\n",
    "    STEPS_PER_EPOCH = 100\n",
    "\n",
    "    # proportional to STEPS_PER_EPOCH\n",
    "    VALIDATION_STEPS = STEPS_PER_EPOCH / 20\n",
    "    \n",
    "config = ShapesConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inititalize_weights_with = \"coco\"  # imagenet, coco, or last\n",
    "\n",
    "if inititalize_weights_with == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "    \n",
    "elif inititalize_weights_with == \"coco\":\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "    \n",
    "elif inititalize_weights_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    model.load_weights(model.find_last()[1], by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
